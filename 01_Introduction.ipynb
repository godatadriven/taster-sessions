{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c279fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<link rel=\"stylesheet\" href=\"https://marysia.nl/assets/GDD/css/custom.css\">\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: change Jupyter Notebook theme to GDD theme\n",
    "from IPython.core.display import HTML\n",
    "HTML(url='https://gdd.li/jupyter-theme')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e882ed8",
   "metadata": {},
   "source": [
    "![footer_logo](https://marysia.nl/assets/GDD/css/logo.png)\n",
    "\n",
    "# Unpacking the \"Black Box\"\n",
    "\n",
    "\n",
    "In this notebook, we shall take our first steps towards understanding our models based on an example dataset on penguin species classification. In this notebook, we will explore two different models -- one easily interpretable, and one slightly more difficult to understand, and investigate how we can *flip the prediction*. That is, change the prediction outcome of our model by altering the feature values. \n",
    "\n",
    "### Outline\n",
    "1. [The data](#loading-in-the-data)\n",
    "1. [Create the model](#dectree)\n",
    "1. [Exercise 1: Flip the Prediction](#ex1) \n",
    "1. [Create SVM model: Flip the Prediction](#svm)\n",
    "1. [Exercise 2](#ex2) \n",
    "\n",
    "\n",
    "![](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/logo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc164293",
   "metadata": {},
   "source": [
    "<a id = 'loading-in-the-data'></a>\n",
    "\n",
    "# 1. The Data\n",
    "The data was collected and made available by Dr. Kristen Gorman and the Palmer Station, Antartica LTER. Their goal was to provide a great dataset for data exploration, visualisation and - in this case - a demonstration of the scikit-learn API. \n",
    "\n",
    "The data set contains measurements for different species of penguins living at the Palmer station:\n",
    "\n",
    "|Field|Description|\n",
    "|:---|:---|\n",
    "|species|The species of the penguin: Adelie, Chinstrap or Gentoo|\n",
    "|island|The island on which the penguin was spotted|\n",
    "|bill_length_mm|The length of the penguin's bill in mm|\n",
    "|bill_depth_mm|The depth of the penguin's bill in mm|\n",
    "|flipper_length_mm|The length of the penguin's flipper in mm|\n",
    "|body_mass_g|The weight of the penguin in grams|\n",
    "|sex|The gender of the penguin - Female or Male|\n",
    "\n",
    "<img src=\"https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/culmen_depth.png\" width=\"600\">\n",
    "\n",
    "### Explore the Data\n",
    "\n",
    "First of all, we load in the data using the Pandas data wrangling library. We make a small alteration to the data -- we drop all datapoints about the Adélie penguin species altogether. This choice was made to better illustrate the various interpretability techniques we will discuss throughout this workshop, but you are free to change the code in order to kep the Adélie penguins. \n",
    "![footer_logo](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/lter_penguins.png) \n",
    "\n",
    "We then explore the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6446131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "penguins = (\n",
    "    pd.read_csv('data/penguins.csv')\n",
    "    .loc[lambda d: d['species'] != 'Adelie']\n",
    "    .dropna()\n",
    ")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a518479",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bccaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=penguins, \n",
    "                x='flipper_length_mm',\n",
    "                y='body_mass_g',\n",
    "                hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39835411",
   "metadata": {},
   "source": [
    "Based on this visualisation on only the flipper length and the body mass, the problem of separating Chinstrap from Gentoo penguins does not seem very challenging. Can you think of a general rule to separate Gentoos from Chinstraps based on this image? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac61af57",
   "metadata": {},
   "source": [
    "Write down your idea here.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc0875",
   "metadata": {},
   "source": [
    "<a id = 'dectree'></a>\n",
    "\n",
    "# 2. Create the Model\n",
    "\n",
    "Nevertheless, we will create a model anyway! In order to do that, we must select the columns (\"features\") we would like to use for the model and the column (\"target\") that we would like to predict. To simplify our problem, we will focus on flipper length and body mass as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b18266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features & target\n",
    "feature_columns = ['flipper_length_mm', 'body_mass_g']\n",
    "target = 'species'\n",
    "\n",
    "# Set X and y\n",
    "X = penguins.loc[:, feature_columns]\n",
    "y = penguins.loc[:, target]\n",
    "\n",
    "print(f'The shape of feature matrix X is: {X.shape}')\n",
    "print(f'The shape of target vector y is: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f36d6",
   "metadata": {},
   "source": [
    "An important goal of machine learning is to create a model that does not only do well on the data that it has already seen, but will also perform well under new circumstances on data that is has not seen before. We call this _generalization_. \n",
    "\n",
    "That's why we want to separate our dataset into two parts:\n",
    "* The _training_ set: this is the data (features and targets) that will guide the learning process. \n",
    "* The _test_ set: this is the data (features and targets) that we will use to _evaluate_ how well our model has learned. \n",
    "\n",
    "<img src=\"images/train-test.png\" width=\"600\">\n",
    "\n",
    "Scikit-learn's `train_test_split` function allows us to split the data in a train- and testset. By default, the test set size is set to 25% and the data is shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "print(f'The size of our feature matrix for the train set is: {X_train.shape}')\n",
    "print(f'The size of our target vector for the train set is: {y_train.shape}')\n",
    "\n",
    "print(f'\\nThe size of our feature matrix for the test set is: {X_test.shape}')\n",
    "print(f'The size of our target vector for the test set is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e2a5a",
   "metadata": {},
   "source": [
    "Now we're ready to create our machine learning model! \n",
    "\n",
    "Scikit-learn has a rich collection of algorithms readily available. Depending on the case you are working on, scikit-learn most likely has a model that will suit your purposes. \n",
    "\n",
    "We will choose a _Decision Tree_ -- a simple algorithm known for its native interpretability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the chosen algorithm.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate the model with the chosen hyperparameters.\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Train the model with the *train* set. \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy with the *test* set. \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c328b57",
   "metadata": {},
   "source": [
    "A >98\\% accuracy! Not bad! \n",
    "\n",
    "Let's see if we can understand what the model has learned in order to make prediction. A big advantage of decision trees is that they are just that - trees, which makes them easy to visualise. Luckily, sklearn has some neat functionality built-in to visualise the tree that was created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431df587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))   # Set the size of the output\n",
    "plot_tree(model,   # pass the model -- this is the tree.\n",
    "          feature_names=X_train.columns,   # give the feature names \n",
    "          class_names=model.classes_,   # give the class names\n",
    "          filled=True);   # different colors for different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd9af9",
   "metadata": {},
   "source": [
    "Our model seemed pretty great, a >98\\% accuracy. However, let's investigate what mistakes were made on the test set -- that is, an example from the test set where the *prediction* did not match the intended *target*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ccd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_test\n",
    "    .assign(target = y_test)\n",
    "    .assign(prediction = model.predict(X_test))\n",
    "    .assign(correct = lambda d: d['target'] == d['prediction'])\n",
    "    .loc[lambda d: ~d['correct']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe7750",
   "metadata": {},
   "source": [
    "<a id = 'ex1'></a>\n",
    "# 3. Exercise\n",
    "<div class=\"exercise\" markdown=\"1\">\n",
    "\n",
    "### Exercise \n",
    "#### Flip the Prediction\n",
    "\n",
    "\n",
    "The Chinstrap with a flipper length of 210 mm and a body mass of 4100 grams was mistaken by the model for a Gentoo penguin. But why? Change the values for flipper_length_mm and/or body_mass_g in the code cell below to change the prediction (from Gentoo to Chinstrap). Use the decision tree as a guide! \n",
    "\n",
    "Write down what change in values caused a change in prediction.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper_length_mm = 210.0   # change this value\n",
    "body_mass_g = 4100.0   # or this value! .. or both. \n",
    "\n",
    "example_datapoint = pd.DataFrame.from_dict({\n",
    "    'flipper_length_mm': [flipper_length_mm], \n",
    "    'body_mass_g': [body_mass_g]\n",
    "})\n",
    "\n",
    "model.predict(example_datapoint)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dafe4612",
   "metadata": {},
   "source": [
    "Write down what change in values caused a change in prediction here..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca0818",
   "metadata": {},
   "source": [
    "# 4. Create SVM model\n",
    "\n",
    "Decision trees are naturally easy to interpret, because they can be visualised. However, decision trees are not the only machine learning models out there. Let us try out a different kind of model on the same dataset and problem, and investigate what changes...\n",
    "\n",
    "In this case, we pick a *support vector classifier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a53546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "model_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9be2e5",
   "metadata": {},
   "source": [
    "Our model performs slightly worse than the decision tree, though still pretty good overall. Let us rehash the earlier example, which the decision tree got wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper_length_mm = 210.0\n",
    "body_mass_g = 4100.0\n",
    "\n",
    "example_datapoint = pd.DataFrame.from_dict({\n",
    "    'flipper_length_mm': [flipper_length_mm], \n",
    "    'body_mass_g': [body_mass_g]\n",
    "})\n",
    "\n",
    "tree_pred = model.predict(example_datapoint)\n",
    "svm_pred = model_svm.predict(example_datapoint)\n",
    "\n",
    "print(f'Prediction decision tree: {tree_pred[0]}')\n",
    "print(f'Prediction SVM: {svm_pred[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bf5b1",
   "metadata": {},
   "source": [
    "The SVM correctly predicts that the penguin with 210mm flipper length and 4100g body bass is a Chinstrap! However, this SVM model isn't perfect -- it makes a few other mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_test\n",
    "    .assign(target = y_test)\n",
    "    .assign(prediction = model_svm.predict(X_test))\n",
    "    .assign(correct = lambda d: d['target'] == d['prediction'])\n",
    "    .loc[lambda d: ~d['correct']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56142656",
   "metadata": {},
   "source": [
    "<a id = 'ex2'></a>\n",
    "# 5. Exercise \n",
    "\n",
    "<div class=\"exercise\" markdown=\"1\">\n",
    "\n",
    "### Exercise \n",
    "#### Flip the Prediction\n",
    "\n",
    "Let's do the same thing as we did with the previous model: change the prediction. Take the Chinstrap with a flipper length of 195 milimeter and a body mass of 4400 grams. The SVM model incorrectly classifies this as a Gentoo. Change the values in the cell below to flip the prediction to a Chinstrap! \n",
    "\n",
    "Write down what change in values caused a change in prediction.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper_length_mm = 195\n",
    "body_mass_g = 4400\n",
    "\n",
    "example_datapoint = pd.DataFrame.from_dict({\n",
    "    'flipper_length_mm': [flipper_length_mm], \n",
    "    'body_mass_g': [body_mass_g]\n",
    "})\n",
    "\n",
    "svm_pred = model_svm.predict(example_datapoint)\n",
    "\n",
    "print(f'Prediction SVM: {svm_pred[0]}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9ce69f4",
   "metadata": {},
   "source": [
    "Write down your changes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b1cef",
   "metadata": {},
   "source": [
    "----------------------------- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
