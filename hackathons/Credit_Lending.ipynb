{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greek-nightmare",
   "metadata": {},
   "source": [
    "<img src=images/gdd-logo.png align=right width=300px style='padding:20px'>\n",
    "\n",
    "# Hackathon: Credit Lending\n",
    "\n",
    "Welcome to the hackathon! In this hackathon, you'll get the opportunity to try out your chosen explainability technique(s) on a dataset on credit lending. \n",
    "\n",
    "\n",
    "### Outline\n",
    "1. [Problem Introduction](#intro)\n",
    "1. [About the data](#data)\n",
    "1. [Creating the model](#model) \n",
    "1. [Assignment](#assignment)\n",
    "\n",
    "<a id = 'intro'></a>\n",
    "\n",
    "## Problem Introduction\n",
    "You work at a Bank in the credit risk department. Your stakeholders want to be able to determine the level of risk for all internal customers, so that if the customer applies for a new product (eg. loan, credit card, overdraft, mortgage) the correct decision can be made as to whether they should get the product or not.\n",
    "\n",
    "The problem with the curent set up is that each individual product has their own way of determining a customer's level of risk. This means that a customer may be rejected to extend their overdraft to €2.000 but accepted to have a loan of €2.000 at the same time. \n",
    "\n",
    "This is providing a bad customer journey which is why the bank wants to consolidate this view of risk so that consistent lending decisions can be made.\n",
    "\n",
    "Often customers who get rejected will complain about their decision so it is important that we can send advisers to them to talk through their situation and suggest a good option for their lending.\n",
    "\n",
    "**Note:** The regulators consider customers are \"unable to repay\" when they have missed 3 payments (on any product) in the last 2 years. \n",
    "\n",
    "<img src=\"images/credit.jpeg\" style=\"display: block;margin-left: auto;margin-right: auto;height: 200px\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-scholarship",
   "metadata": {},
   "source": [
    "<a id = 'data'></a>\n",
    "\n",
    "## About the data\n",
    "\n",
    "We have access to data on a large number of customers.\n",
    "\n",
    "The unable to repay flag is named `bad_flag` and is determined using the description above. The rest of the features in the dataset are described below:\n",
    "\n",
    "|Variable Name|\tDescription\t|Type|\n",
    "|:---|:---|:---|\n",
    "|rev_unsecured|\tTotal balance on loans (no real estate) as a percentage of the total loan taken \t|percentage|\n",
    "|age\t|Age of borrower in years\t|integer|\n",
    "|days_past_due_30\t|Number of times borrower has been 30-59 days past due in the last |2 years |integer|\n",
    "|debt_ratio\t|Monthly debt payments, alimony, living costs divided by monthy gross income|\tfloat (%)|\n",
    "|income |\tMonthly income\t|float|\n",
    "|num_credit\t|Number of Open loans (car loan, mortgage, credit cards etc.)\t|integer|\n",
    "|num_days_late\t|Number of times borrower has been 90 days or more past due.\t|integer|\n",
    "|num_realestate\t|Number of mortgage and real estate loans including home equity lines of credit\t|integer|\n",
    "|days_past_due_60\t|Number of times borrower has been 60-89 days past due in the last 2 years.|\tinteger|\n",
    "|num_deps|\tNumber of dependents in family excluding themselves (spouse, children etc.)\t|integer|\n",
    "|bad_flag\t|Missed 3 monthly payments or more in past two years |\tY/N|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b62ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "credit = pd.read_csv('data/credit.csv')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b914b8",
   "metadata": {},
   "source": [
    "<a id = 'model'></a>\n",
    "\n",
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69a257",
   "metadata": {},
   "source": [
    "We start by loading the data, selecting the features and target and creating a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['num_realestate', 'debt_ratio', 'income', 'num_credit', 'num_deps']\n",
    "X = credit.loc[:, features]\n",
    "y = credit.loc[:, 'bad_flag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bbf4d",
   "metadata": {},
   "source": [
    "Because there are some missing values in two of the columns, we'll impute those using SimpleImpter within ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "column_imputer = ColumnTransformer(\n",
    "    [\n",
    "        ('imp_inc', SimpleImputer(strategy='mean'), ['income']),\n",
    "        ('imp_deps', SimpleImputer(strategy='most_frequent'), ['num_deps'])\n",
    "    ]\n",
    "    , remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5d8ac",
   "metadata": {},
   "source": [
    "Now we can create a pipeline with both the preprocessing steps and the model we want, and see how our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('imputer', column_imputer),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d8231",
   "metadata": {},
   "source": [
    "<a id = 'assignment'></a>\n",
    "\n",
    "# <mark>Assignment</mark>\n",
    "\n",
    "### Theory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de0f59",
   "metadata": {},
   "source": [
    "1. Read the problem description. Which type of explainability method do you imagine would be most suitable for this problem: \n",
    "    - Local (explains one single prediction) or global (explains model behaviour)? \n",
    "    - Feature importance (determining which features have the biggest impact on your predictions) or feature sensitivity (determining how predictions would be affected to changes in feature values)? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d7cd743",
   "metadata": {},
   "source": [
    "Write your answers here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064bdee",
   "metadata": {},
   "source": [
    "2. Are there any inherently interpretable models that spring to mind that can help you address the need for explainability for this problem? The model implemented is a Random Forest. Was that a good choice?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3418202",
   "metadata": {},
   "source": [
    "Write your answers here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f64236",
   "metadata": {},
   "source": [
    "3. What model-agnostic techniques would be appropriate to address the need for explainability for this problem?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26fa2f84",
   "metadata": {},
   "source": [
    "Write your answers here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c4e5c",
   "metadata": {},
   "source": [
    "#### Bonus \n",
    "4. Explainability methods can be used to enhance the customers' understanding of the model's decision making process. \n",
    "\n",
    "    What are the pros & cons (for the business in question) to use explainability methods this way? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa622ad7",
   "metadata": {},
   "source": [
    "Write your answers here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0fcee",
   "metadata": {},
   "source": [
    "5. Some explainability methods are less useful when features are highly correlated. Is that applicable to this dataset, and if so, what can you do to still interpret your model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d1c34a2",
   "metadata": {},
   "source": [
    "Write your answers here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bec1d9",
   "metadata": {},
   "source": [
    "### Do-it-yourself\n",
    "The explainability techniques covered in the workshop were: \n",
    "* Ceteris Paribus (local sensitivity)\n",
    "* Prediction Break-Down (local feature importance)\n",
    "* Permutation Feature Importance (global feature importance)\n",
    "* Partial Dependence Plots (global sensitivity)\n",
    "\n",
    "Implement the technique that you deem most appropriate for this problem. Consider both the problem statement, as well as the advantages and disadvantages of each method. Refer back to the [slides](https://github.com/marysia/explainability-workshop/blob/master/presentation.pdf) if necessary. \n",
    "\n",
    "#### Bonus challenges: \n",
    "* Also try out the other explainability techniques!\n",
    "* Use a Decision Tree model and visualise the decision tree. Experiment with various settings for `max_depth`. How does this influence the model's performance and the degree of explainability? \n",
    "* Find feature importances of the Random Forest model pipeline. Compare it to the results of Permutation Feature Importance. \n",
    "* Try out any other model you'd like.\n",
    "* Find example-based explanations. \n",
    "    * Counterfactuals\n",
    "    * Adversarial examples\n",
    "* Try k-Nearest Neighbors classifier and extract the example data points that explain a specific prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debc0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "controlling-alfred",
   "metadata": {},
   "source": [
    "<img src='images/gdd-logo.png' align=right width=300px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
